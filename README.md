In this project, we aim to predict bank customer defaults (label 0: Non-Default, label 1: Default) depending on a plethora of features. In this process, we would like to both achieve the highest accuracy possible, the lowest recall possible on Customer defaults, while also understanding the main features that can lead to a customer default. To achieve both of our goals, we decided to follow this pipeline:

    Understand our independent features, as well as our target variable.
    Prepare and process our dataset.
    Feature Engineering.
    Machine Learning Models, Hyperparameter tunning, and Evaluation.

Table of content for Jupyter Notebook

    Data Loading and Exploratory Data Analysis
    Investigating Missing Values
    Handling Outliers and Correcting Skewness
    Encoding Categorical Variables
    Handling the Imbalance in the dataset
    Running Logistic Regression
    Conclusions and Evaluations
